# ğŸ‘ï¸ Computer Vision

## Table of Contents
- [Introduction](#introduction)
- [Image Fundamentals](#image-fundamentals)
- [Convolutional Neural Networks](#convolutional-neural-networks)
- [CNN Architectures](#cnn-architectures)
- [Object Detection](#object-detection)
- [Image Segmentation](#image-segmentation)
- [Vision Transformers](#vision-transformers)
- [Practical Tips](#practical-tips)

---

## Introduction

Computer Vision enables machines to interpret and understand visual information from the world.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMPUTER VISION TASKS                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   IMAGE CLASSIFICATION        OBJECT DETECTION        SEGMENTATION     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚               â”‚          â”‚ â”Œâ”€â”€â”€â”         â”‚      â”‚â–“â–“â–“â–“â–“          â”‚  â”‚
â”‚   â”‚    ğŸ±         â”‚          â”‚ â”‚ğŸ±â”‚ â”Œâ”€â”€â”€â”   â”‚      â”‚â–“â–“ğŸ±â–“          â”‚  â”‚
â”‚   â”‚               â”‚          â”‚ â””â”€â”€â”€â”˜ â”‚ğŸ•â”‚   â”‚      â”‚â–“â–“â–“â–“â–“ â–ˆâ–ˆâ–ˆâ–ˆ     â”‚  â”‚
â”‚   â”‚               â”‚          â”‚       â””â”€â”€â”€â”˜   â”‚      â”‚      â–ˆğŸ•â–ˆ     â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚   "cat" (0.95)               cat: [x,y,w,h]          Pixel-level       â”‚
â”‚                              dog: [x,y,w,h]          labels            â”‚
â”‚                                                                         â”‚
â”‚   POSE ESTIMATION            IMAGE GENERATION        DEPTH ESTIMATION  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚     â—         â”‚          â”‚               â”‚      â”‚ â–‘â–‘â–‘â–’â–’â–’â–“â–“â–“    â”‚  â”‚
â”‚   â”‚    /|\        â”‚          â”‚   Text â†’      â”‚      â”‚ â–‘â–‘â–’â–’â–“â–“â–“â–“â–“    â”‚  â”‚
â”‚   â”‚    / \        â”‚          â”‚   Image       â”‚      â”‚ â–‘â–’â–’â–“â–“â–ˆâ–ˆâ–ˆ     â”‚  â”‚
â”‚   â”‚   Skeleton    â”‚          â”‚               â”‚      â”‚  Near â†’ Far   â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Image Fundamentals

### Digital Image Representation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    IMAGE AS A TENSOR                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   RGB Image: (Height Ã— Width Ã— Channels)                               â”‚
â”‚                                                                         â”‚
â”‚   Example: 224 Ã— 224 Ã— 3                                               â”‚
â”‚                                                                         â”‚
â”‚        Width (224)                                                      â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚
â”‚    â”‚ [R G B] [R G B]  â”‚                                                â”‚
â”‚  H â”‚ [R G B] [R G B]  â”‚  Each pixel: 3 values (0-255)                  â”‚
â”‚  e â”‚ [R G B] [R G B]  â”‚                                                â”‚
â”‚  i â”‚    ...           â”‚  Total values: 224 Ã— 224 Ã— 3                   â”‚
â”‚  g â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                = 150,528                       â”‚
â”‚  h                                                                      â”‚
â”‚  t                                                                      â”‚
â”‚                                                                         â”‚
â”‚   Grayscale: 224 Ã— 224 Ã— 1                                             â”‚
â”‚   RGBA: 224 Ã— 224 Ã— 4 (with alpha channel)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Image Preprocessing

```python
# Common preprocessing pipeline
transforms.Compose([
    transforms.Resize(256),            # Resize shorter side to 256
    transforms.CenterCrop(224),        # Crop center 224Ã—224
    transforms.ToTensor(),             # Convert to [0, 1] tensor
    transforms.Normalize(              # ImageNet normalization
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])
```

---

## Convolutional Neural Networks

### Convolution Operation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    2D CONVOLUTION                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   Input (5Ã—5)           Kernel (3Ã—3)         Output (3Ã—3)              â”‚
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚   â”‚ 1  2  3  4  5â”‚       â”‚ 1  0 -1â”‚         â”‚ *  *  * â”‚               â”‚
â”‚   â”‚ 6  7  8  9 10â”‚   *   â”‚ 2  0 -2â”‚    =    â”‚ *  *  * â”‚               â”‚
â”‚   â”‚11 12 13 14 15â”‚       â”‚ 1  0 -1â”‚         â”‚ *  *  * â”‚               â”‚
â”‚   â”‚16 17 18 19 20â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚   â”‚21 22 23 24 25â”‚                                                      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                       â”‚
â”‚                                                                         â”‚
â”‚   Example calculation for top-left output:                              â”‚
â”‚   1Ã—1 + 2Ã—0 + 3Ã—(-1) + 6Ã—2 + 7Ã—0 + 8Ã—(-2) + 11Ã—1 + 12Ã—0 + 13Ã—(-1)     â”‚
â”‚   = 1 - 3 + 12 - 16 + 11 - 13 = -8                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Concepts

**Stride**: How much the kernel moves
```
Stride = 1: Move 1 pixel at a time
Stride = 2: Move 2 pixels (downsamples by 2Ã—)
```

**Padding**: Adding zeros around input
```
Same padding: Output size = Input size
Valid padding: No padding (output smaller)
```

**Output Size Formula:**
$$O = \frac{I - K + 2P}{S} + 1$$
Where: I = input size, K = kernel size, P = padding, S = stride

### Pooling Layers

```
Max Pooling (2Ã—2, stride=2):

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1  2 â”‚ 3  4 â”‚         â”‚ 6 â”‚ 8 â”‚
â”‚ 5  6 â”‚ 7  8 â”‚   â†’     â”œâ”€â”€â”€â”¼â”€â”€â”€â”¤
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤         â”‚14 â”‚16 â”‚
â”‚ 9 10 â”‚11 12 â”‚         â””â”€â”€â”€â”´â”€â”€â”€â”˜
â”‚13 14 â”‚15 16 â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
  4Ã—4                    2Ã—2
```

### Feature Hierarchy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CNN FEATURE HIERARCHY                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   Layer 1              Layer 3              Layer 5                    â”‚
â”‚   (Early)              (Middle)             (Deep)                     â”‚
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”                    â”‚
â”‚   â”‚ â”€â”€â”€ â”‚              â”‚ â—¢â—£  â”‚              â”‚ ğŸ‘ï¸  â”‚                    â”‚
â”‚   â”‚ â”‚â”‚â”‚ â”‚              â”‚ â—‹â—‹  â”‚              â”‚ ğŸ‘‚  â”‚                    â”‚
â”‚   â”‚ /// â”‚              â”‚ â—¡â—¡  â”‚              â”‚ ğŸ±  â”‚                    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                                                                         â”‚
â”‚   Edges,               Textures,            Object parts,              â”‚
â”‚   colors               patterns             full objects               â”‚
â”‚   (low-level)          (mid-level)          (high-level)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## CNN Architectures

### Evolution Timeline

```
Year:  2012       2014       2015       2016       2017       2020+
       â”‚          â”‚          â”‚          â”‚          â”‚          â”‚
       â–¼          â–¼          â–¼          â–¼          â–¼          â–¼
    AlexNet â†’ VGGNet â†’ GoogLeNet â†’ ResNet â†’ DenseNet â†’ EfficientNet
       â”‚          â”‚          â”‚          â”‚          â”‚          â”‚
    8 layers   19 layers  22 layers  152 layers  Dense     Scaling
    60M params 138M params Inception  Skip       connections
```

### LeNet-5 (1998)

The foundational CNN architecture:

```
Input     Conv1    Pool1    Conv2    Pool2    FC1    FC2    Output
32Ã—32  â†’  28Ã—28  â†’ 14Ã—14  â†’ 10Ã—10  â†’  5Ã—5  â†’  120  â†’  84  â†’  10
 Ã—1       Ã—6       Ã—6       Ã—16      Ã—16
```

### AlexNet (2012)

```
Input: 224Ã—224Ã—3
â”œâ”€â”€ Conv1: 96 filters, 11Ã—11, stride 4
â”œâ”€â”€ MaxPool: 3Ã—3, stride 2
â”œâ”€â”€ Conv2: 256 filters, 5Ã—5
â”œâ”€â”€ MaxPool: 3Ã—3, stride 2
â”œâ”€â”€ Conv3: 384 filters, 3Ã—3
â”œâ”€â”€ Conv4: 384 filters, 3Ã—3
â”œâ”€â”€ Conv5: 256 filters, 3Ã—3
â”œâ”€â”€ MaxPool: 3Ã—3, stride 2
â”œâ”€â”€ FC: 4096
â”œâ”€â”€ FC: 4096
â””â”€â”€ FC: 1000 (output)
```

### VGGNet (2014)

Key insight: **Deeper is better with small (3Ã—3) filters**

```
VGG-16:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Conv3-64  Ã—2  â†’ MaxPool                 â”‚
â”‚ Conv3-128 Ã—2  â†’ MaxPool                 â”‚
â”‚ Conv3-256 Ã—3  â†’ MaxPool                 â”‚
â”‚ Conv3-512 Ã—3  â†’ MaxPool                 â”‚
â”‚ Conv3-512 Ã—3  â†’ MaxPool                 â”‚
â”‚ FC-4096 â†’ FC-4096 â†’ FC-1000             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ResNet (2015)

**Key innovation: Skip/Residual connections**

$$y = F(x) + x$$

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RESIDUAL BLOCK                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚           x                                                             â”‚
â”‚           â”‚                                                             â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                                       â”‚
â”‚     â”‚           â”‚                                                       â”‚
â”‚     â–¼           â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”        â”‚ (Identity/Skip Connection)                           â”‚
â”‚  â”‚Conv â”‚        â”‚                                                       â”‚
â”‚  â””â”€â”€â”¬â”€â”€â”˜        â”‚                                                       â”‚
â”‚     â”‚           â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â–¼â”€â”€â”        â”‚                                                       â”‚
â”‚  â”‚ BN  â”‚        â”‚                                                       â”‚
â”‚  â””â”€â”€â”¬â”€â”€â”˜        â”‚                                                       â”‚
â”‚     â”‚           â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â–¼â”€â”€â”        â”‚                                                       â”‚
â”‚  â”‚ReLU â”‚        â”‚                                                       â”‚
â”‚  â””â”€â”€â”¬â”€â”€â”˜        â”‚                                                       â”‚
â”‚     â”‚           â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â–¼â”€â”€â”        â”‚                                                       â”‚
â”‚  â”‚Conv â”‚        â”‚                                                       â”‚
â”‚  â””â”€â”€â”¬â”€â”€â”˜        â”‚                                                       â”‚
â”‚     â”‚           â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â–¼â”€â”€â”        â”‚                                                       â”‚
â”‚  â”‚ BN  â”‚        â”‚                                                       â”‚
â”‚  â””â”€â”€â”¬â”€â”€â”˜        â”‚                                                       â”‚
â”‚     â”‚           â”‚                                                       â”‚
â”‚     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                                       â”‚
â”‚           â”‚                                                             â”‚
â”‚        â”Œâ”€â”€â–¼â”€â”€â”                                                          â”‚
â”‚        â”‚  +  â”‚  â† Element-wise addition                                â”‚
â”‚        â””â”€â”€â”¬â”€â”€â”˜                                                          â”‚
â”‚           â”‚                                                             â”‚
â”‚        â”Œâ”€â”€â–¼â”€â”€â”                                                          â”‚
â”‚        â”‚ReLU â”‚                                                          â”‚
â”‚        â””â”€â”€â”¬â”€â”€â”˜                                                          â”‚
â”‚           â”‚                                                             â”‚
â”‚           y = F(x) + x                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Object Detection

### Two-Stage Detectors

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    R-CNN FAMILY                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   R-CNN (2014):                                                        â”‚
â”‚   Image â†’ Region Proposals (~2000) â†’ CNN â†’ SVM                         â”‚
â”‚   Slow: Process each region separately                                 â”‚
â”‚                                                                         â”‚
â”‚   Fast R-CNN (2015):                                                   â”‚
â”‚   Image â†’ CNN â†’ RoI Pooling â†’ FC â†’ Class + BBox                        â”‚
â”‚   Faster: Share CNN computation                                        â”‚
â”‚                                                                         â”‚
â”‚   Faster R-CNN (2015):                                                 â”‚
â”‚   Image â†’ CNN â†’ RPN â†’ RoI Pooling â†’ FC â†’ Class + BBox                  â”‚
â”‚   Fastest: Learn region proposals                                      â”‚
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                    FASTER R-CNN                                  â”‚  â”‚
â”‚   â”‚                                                                  â”‚  â”‚
â”‚   â”‚   Image â†’ Backbone â†’ Feature Map                                â”‚  â”‚
â”‚   â”‚               CNN      â”‚                                        â”‚  â”‚
â”‚   â”‚                        â”‚                                        â”‚  â”‚
â”‚   â”‚                   â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                                   â”‚  â”‚
â”‚   â”‚                   â”‚   RPN   â”‚ Region Proposal Network           â”‚  â”‚
â”‚   â”‚                   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                   â”‚  â”‚
â”‚   â”‚                        â”‚ (proposals)                            â”‚  â”‚
â”‚   â”‚                   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”                                   â”‚  â”‚
â”‚   â”‚                   â”‚RoI Pool â”‚                                   â”‚  â”‚
â”‚   â”‚                   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                   â”‚  â”‚
â”‚   â”‚                   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”                                   â”‚  â”‚
â”‚   â”‚                   â”‚   FC    â”‚                                   â”‚  â”‚
â”‚   â”‚                   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                   â”‚  â”‚
â”‚   â”‚                   â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                                   â”‚  â”‚
â”‚   â”‚                   â–¼         â–¼                                   â”‚  â”‚
â”‚   â”‚               Class      BBox                                   â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Single-Stage Detectors (YOLO, SSD)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    YOLO (You Only Look Once)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   1. Divide image into SÃ—S grid                                        â”‚
â”‚   2. Each cell predicts B bounding boxes                               â”‚
â”‚   3. Each box: (x, y, w, h, confidence) + class probabilities          â”‚
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                                                                  â”‚  â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”                                 â”‚  â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚                                 â”‚  â”‚
â”‚   â”‚   â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤                                 â”‚  â”‚
â”‚   â”‚   â”‚   â”‚   â”‚ â—‹ â”‚   â”‚   â”‚   â”‚   â”‚  â—‹ = Cell responsible for      â”‚  â”‚
â”‚   â”‚   â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤      object center             â”‚  â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚                                 â”‚  â”‚
â”‚   â”‚   â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤  Each cell predicts:           â”‚  â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚ â–¢ â”‚   â”‚   â”‚   â”‚  â€¢ B bounding boxes            â”‚  â”‚
â”‚   â”‚   â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤  â€¢ Confidence scores           â”‚  â”‚
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”‚  â€¢ Class probabilities          â”‚  â”‚
â”‚   â”‚   â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜                                 â”‚  â”‚
â”‚   â”‚         7Ã—7 grid                                                 â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                         â”‚
â”‚   Advantages: Real-time (45+ FPS), End-to-end training                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Evaluation: IoU and mAP

**Intersection over Union (IoU):**
$$\text{IoU} = \frac{\text{Area of Overlap}}{\text{Area of Union}}$$

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Predicted    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ”‚â–ˆ    â”‚   IoU = Intersection / Union
â”‚   â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ”‚â–ˆ    â”‚       = 4 / 12
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”˜â–ˆ    â”‚       = 0.33
â”‚     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      Ground Truth

IoU > 0.5: Typically considered a match
```

---

## Image Segmentation

### Types of Segmentation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SEGMENTATION TYPES                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   Semantic Segmentation    Instance Segmentation    Panoptic            â”‚
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â”‚       â”‚â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â”‚       â”‚â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â”‚    â”‚
â”‚   â”‚â–“â–“catâ–“â–“â–“â–“â–“â–“â–“â–“â–“â”‚       â”‚â–“cat1â–“â–“â–“â–“â–“â–“â–“â–“â–“â”‚       â”‚â–“cat1â–“â–“â–“â–“â–“â–“â–“â–“â–“â”‚    â”‚
â”‚   â”‚â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â”‚       â”‚â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â”‚       â”‚â–“â–“â–“â–“skyâ–“â–“â–“â–“â–“â–“â–“â”‚    â”‚
â”‚   â”‚â–“â–“â–“â–“catâ–“â–“â–“â–“â–“â–“â–“â”‚       â”‚â–“â–“â–“â–“cat2â–“â–“â–“â–“â–“â–“â”‚       â”‚â–“â–“â–“cat2â–“grassâ–“â”‚    â”‚
â”‚   â”‚â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â”‚       â”‚â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â”‚       â”‚â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                         â”‚
â”‚   All cats = one class   Each cat = separate   Both things &           â”‚
â”‚                                                stuff classes            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### U-Net Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    U-NET ARCHITECTURE                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   Encoder (Contracting)              Decoder (Expanding)               â”‚
â”‚                                                                         â”‚
â”‚   Input â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Output      â”‚
â”‚     â”‚                                                         â–²         â”‚
â”‚     â–¼                                                         â”‚         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”  copy & crop  â”Œâ”€â”€â”€â”€â”                               â”Œâ”€â”€â”€â”€â”     â”‚
â”‚   â”‚    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚    â”‚         Skip connections      â”‚    â”‚     â”‚
â”‚   â””â”€â”€â”¬â”€â”˜               â””â”€â”€â”¬â”€â”˜         preserve spatial      â””â”€â”€â–²â”€â”˜     â”‚
â”‚      â”‚                    â–²           information             â”‚         â”‚
â”‚      â–¼                    â”‚                                   â”‚         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”  copy & crop  â”Œâ”€â”€â”€â”€â”                               â”Œâ”€â”€â”€â”€â”     â”‚
â”‚   â”‚    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚    â”‚                               â”‚    â”‚     â”‚
â”‚   â””â”€â”€â”¬â”€â”˜               â””â”€â”€â”¬â”€â”˜                               â””â”€â”€â–²â”€â”˜     â”‚
â”‚      â”‚                    â–²                                   â”‚         â”‚
â”‚      â–¼                    â”‚                                   â”‚         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”  copy & crop  â”Œâ”€â”€â”€â”€â”                               â”Œâ”€â”€â”€â”€â”     â”‚
â”‚   â”‚    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚    â”‚                               â”‚    â”‚     â”‚
â”‚   â””â”€â”€â”¬â”€â”˜               â””â”€â”€â”€â”€â”˜                               â””â”€â”€â–²â”€â”˜     â”‚
â”‚      â”‚                                                         â”‚         â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                         Bottleneck                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Vision Transformers

### ViT (Vision Transformer)

Applying transformers directly to images:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VISION TRANSFORMER (ViT)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   1. Split image into patches (e.g., 16Ã—16)                            â”‚
â”‚   2. Flatten and linearly embed patches                                 â”‚
â”‚   3. Add position embeddings                                            â”‚
â”‚   4. Feed to standard Transformer encoder                              â”‚
â”‚   5. Use [CLS] token for classification                                â”‚
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚     Image (224Ã—224)          Patches (14Ã—14 = 196)            â”‚    â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”                 â”‚    â”‚
â”‚   â”‚   â”‚               â”‚         â”‚ 1 â”‚ 2 â”‚ 3 â”‚...â”‚                 â”‚    â”‚
â”‚   â”‚   â”‚               â”‚   â†’     â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤                 â”‚    â”‚
â”‚   â”‚   â”‚               â”‚         â”‚...â”‚...â”‚...â”‚196â”‚                 â”‚    â”‚
â”‚   â”‚   â”‚               â”‚         â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜                 â”‚    â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚    â”‚
â”‚   â”‚                                                               â”‚    â”‚
â”‚   â”‚   [CLS] + Patch Embeddings + Position Embeddings              â”‚    â”‚
â”‚   â”‚      â†“                                                        â”‚    â”‚
â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚    â”‚
â”‚   â”‚   â”‚         Transformer Encoder             â”‚ Ã— L layers     â”‚    â”‚
â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚    â”‚
â”‚   â”‚      â†“                                                        â”‚    â”‚
â”‚   â”‚   [CLS] token â†’ MLP Head â†’ Class prediction                   â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CNN vs ViT

| Aspect | CNN | ViT |
|--------|-----|-----|
| Inductive bias | Strong (locality) | Weak |
| Data efficiency | Better with small data | Needs large data |
| Global context | Limited (needs depth) | Built-in (attention) |
| Compute | O(n) | O(nÂ²) |
| Transfer learning | Good | Excellent (at scale) |

---

## Practical Tips

### 1. Data Augmentation

```python
transforms.Compose([
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.RandomCrop(224, padding=4),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
])
```

### 2. Transfer Learning

```python
# Load pretrained model
model = torchvision.models.resnet50(pretrained=True)

# Freeze backbone
for param in model.parameters():
    param.requires_grad = False

# Replace classifier
model.fc = nn.Linear(2048, num_classes)
```

### 3. Learning Rate Scheduling

```python
# Cosine annealing
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
    optimizer, T_max=num_epochs
)

# One cycle
scheduler = torch.optim.lr_scheduler.OneCycleLR(
    optimizer, max_lr=0.01, total_steps=total_steps
)
```

### 4. Common Issues

| Issue | Solution |
|-------|----------|
| Overfitting | More augmentation, dropout, smaller model |
| Underfitting | Larger model, more training time |
| Slow training | Mixed precision (FP16), gradient checkpointing |
| Class imbalance | Weighted loss, oversampling |

---

## Resources

- ğŸ“„ **Paper**: "ImageNet Classification with Deep CNNs" (AlexNet)
- ğŸ“„ **Paper**: "Deep Residual Learning for Image Recognition" (ResNet)
- ğŸ“„ **Paper**: "An Image is Worth 16x16 Words" (ViT)
- ğŸ“ **Course**: Stanford CS231n - CNNs for Visual Recognition
- ğŸ”§ **Library**: torchvision, OpenCV, Detectron2

---

ğŸŒ [Back to Notes](README.md) | ğŸ”— [Visit jgcks.com](https://www.jgcks.com)

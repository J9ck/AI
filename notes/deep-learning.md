# ğŸ§  Deep Learning

## Table of Contents
- [Introduction](#introduction)
- [Neural Network Basics](#neural-network-basics)
- [Backpropagation](#backpropagation)
- [Activation Functions](#activation-functions)
- [Optimization](#optimization)
- [Regularization](#regularization)
- [Architectures](#architectures)
- [Practical Tips](#practical-tips)

---

## Introduction

Deep Learning is a subset of machine learning based on artificial neural networks with multiple layers (hence "deep"). These networks can automatically learn hierarchical representations of data.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AI â†’ ML â†’ DEEP LEARNING                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚    â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®   â”‚
â”‚    â”‚                  ARTIFICIAL INTELLIGENCE                       â”‚   â”‚
â”‚    â”‚    â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®      â”‚   â”‚
â”‚    â”‚    â”‚              MACHINE LEARNING                      â”‚      â”‚   â”‚
â”‚    â”‚    â”‚    â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®      â”‚      â”‚   â”‚
â”‚    â”‚    â”‚    â”‚            DEEP LEARNING               â”‚      â”‚      â”‚   â”‚
â”‚    â”‚    â”‚    â”‚  â€¢ Neural Networks                     â”‚      â”‚      â”‚   â”‚
â”‚    â”‚    â”‚    â”‚  â€¢ CNNs, RNNs, Transformers           â”‚      â”‚      â”‚   â”‚
â”‚    â”‚    â”‚    â”‚  â€¢ Representation Learning            â”‚      â”‚      â”‚   â”‚
â”‚    â”‚    â”‚    â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯      â”‚      â”‚   â”‚
â”‚    â”‚    â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯      â”‚   â”‚
â”‚    â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Neural Network Basics

### The Perceptron

The simplest neural network unit:

```
        xâ‚ â”€â”€[wâ‚]â”€â”€â”
                    â”‚
        xâ‚‚ â”€â”€[wâ‚‚]â”€â”€â”¼â”€â”€[Î£]â”€â”€[f]â”€â”€ y
                    â”‚
        xâ‚ƒ â”€â”€[wâ‚ƒ]â”€â”€â”˜
                    â”‚
             b â”€â”€â”€â”€â”€â”˜
```

$$y = f\left(\sum_{i=1}^{n} w_i x_i + b\right) = f(W^T X + b)$$

### Multi-Layer Perceptron (MLP)

```
    INPUT          HIDDEN          HIDDEN          OUTPUT
    LAYER          LAYER 1         LAYER 2         LAYER
    
     (xâ‚)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€(hâ‚â‚)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€(hâ‚‚â‚)
        â•²        â•±    â•²        â•±    â•²        â•²
         â•²      â•±      â•²      â•±      â•²        (yâ‚)
     (xâ‚‚)â”€â”€â•²â”€â”€â•±â”€â”€â”€â”€â”€â”€â”€â”€(hâ‚â‚‚)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€(hâ‚‚â‚‚)â”€â”€â”€â•±
            â•²â•±              â•²â•±            â•²  â•±
            â•±â•²              â•±â•²            â•±â•²
     (xâ‚ƒ)â”€â”€â•±â”€â”€â•²â”€â”€â”€â”€â”€â”€â”€â”€(hâ‚â‚ƒ)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€(hâ‚‚â‚ƒ)â”€â”€â”€â•²
         â•±      â•²      â•±      â•²      â•±        (yâ‚‚)
        â•±        â•²    â•±        â•²    â•±
     (xâ‚„)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€(hâ‚â‚„)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€(hâ‚‚â‚„)
```

### Forward Pass

For layer $l$:
$$Z^{[l]} = W^{[l]} A^{[l-1]} + b^{[l]}$$
$$A^{[l]} = g^{[l]}(Z^{[l]})$$

Where:
- $W^{[l]}$ = weight matrix for layer $l$
- $A^{[l]}$ = activations of layer $l$
- $g^{[l]}$ = activation function for layer $l$

---

## Backpropagation

The algorithm for training neural networks by computing gradients.

### Chain Rule

$$\frac{\partial L}{\partial w} = \frac{\partial L}{\partial a} \cdot \frac{\partial a}{\partial z} \cdot \frac{\partial z}{\partial w}$$

### Backward Pass Algorithm

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKPROPAGATION FLOW                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚    FORWARD PASS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º   â”‚
â”‚                                                                         â”‚
â”‚    Input    Layer 1    Layer 2    Layer 3    Output    Loss            â”‚
â”‚      X   â†’   Wâ‚,bâ‚  â†’  Wâ‚‚,bâ‚‚  â†’  Wâ‚ƒ,bâ‚ƒ  â†’    Å·    â†’    L             â”‚
â”‚                                                                         â”‚
â”‚    â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ BACKWARD PASS  â”‚
â”‚                                                                         â”‚
â”‚     âˆ‚L       âˆ‚L        âˆ‚L        âˆ‚L         âˆ‚L                         â”‚
â”‚    â”€â”€â”€â”€     â”€â”€â”€â”€      â”€â”€â”€â”€      â”€â”€â”€â”€       â”€â”€â”€â”€                        â”‚
â”‚     âˆ‚X      âˆ‚Wâ‚       âˆ‚Wâ‚‚       âˆ‚Wâ‚ƒ        âˆ‚Å·                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

For output layer:
$$\delta^{[L]} = \frac{\partial L}{\partial A^{[L]}} \odot g'^{[L]}(Z^{[L]})$$

For hidden layers:
$$\delta^{[l]} = (W^{[l+1]})^T \delta^{[l+1]} \odot g'^{[l]}(Z^{[l]})$$

Weight gradients:
$$\frac{\partial L}{\partial W^{[l]}} = \delta^{[l]} (A^{[l-1]})^T$$

---

## Activation Functions

| Function | Formula | Derivative | Range |
|----------|---------|------------|-------|
| **Sigmoid** | $\sigma(x) = \frac{1}{1+e^{-x}}$ | $\sigma(x)(1-\sigma(x))$ | (0, 1) |
| **Tanh** | $\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$ | $1 - \tanh^2(x)$ | (-1, 1) |
| **ReLU** | $\max(0, x)$ | $\begin{cases} 1 & x > 0 \\ 0 & x \leq 0 \end{cases}$ | [0, âˆ) |
| **Leaky ReLU** | $\max(0.01x, x)$ | $\begin{cases} 1 & x > 0 \\ 0.01 & x \leq 0 \end{cases}$ | (-âˆ, âˆ) |
| **ELU** | $\begin{cases} x & x > 0 \\ \alpha(e^x - 1) & x \leq 0 \end{cases}$ | $\begin{cases} 1 & x > 0 \\ f(x) + \alpha & x \leq 0 \end{cases}$ | (-Î±, âˆ) |
| **GELU** | $x \cdot \Phi(x)$ | Complex | (-âˆ, âˆ) |
| **Swish** | $x \cdot \sigma(x)$ | Complex | (-âˆ, âˆ) |

### Visualization

```
         Sigmoid              ReLU              Leaky ReLU
     1 â”¤    â•­â”€â”€â”€â”€â”€â”€â”€â”€      â”¤        â•±          â”¤        â•±
       â”‚   â•±               â”‚       â•±           â”‚       â•±
   0.5 â”¤â”€â”€â•¯                â”‚      â•±            â”‚      â•±
       â”‚                   â”‚     â•±             â”‚    â•±
     0 â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     0 â”¼â”€â”€â”€â”€â•±â”€â”€â”€â”€â”€â”€â”€     0 â”¼â”€â”€â”€â•±â”€â”€â”€â”€â”€â”€
       â”‚                   â”‚                   â”‚  â•±
       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€        â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€        â””â”€â•±â”€â”€â”€â”¬â”€â”€â”€â”€â”€
            -4  4               -4  4              -4  4
```

### When to Use What

- **ReLU**: Default choice for hidden layers
- **Leaky ReLU/ELU**: When facing dying ReLU problem
- **GELU/Swish**: Modern architectures (Transformers)
- **Sigmoid**: Output layer for binary classification
- **Softmax**: Output layer for multi-class classification

---

## Optimization

### Gradient Descent Variants

#### 1. Vanilla Gradient Descent
$$\theta = \theta - \alpha \nabla_\theta L(\theta)$$

#### 2. Momentum
$$v_t = \gamma v_{t-1} + \alpha \nabla_\theta L(\theta)$$
$$\theta = \theta - v_t$$

#### 3. RMSprop
$$E[g^2]_t = \gamma E[g^2]_{t-1} + (1-\gamma) g_t^2$$
$$\theta = \theta - \frac{\alpha}{\sqrt{E[g^2]_t + \epsilon}} g_t$$

#### 4. Adam (Recommended)
Combines momentum and RMSprop:

$$m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t$$
$$v_t = \beta_2 v_{t-1} + (1-\beta_2) g_t^2$$
$$\hat{m}_t = \frac{m_t}{1-\beta_1^t}$$
$$\hat{v}_t = \frac{v_t}{1-\beta_2^t}$$
$$\theta = \theta - \frac{\alpha}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t$$

Default values: $\beta_1 = 0.9$, $\beta_2 = 0.999$, $\epsilon = 10^{-8}$

### Learning Rate Schedules

```
Constant        Step Decay       Exponential      Cosine Annealing
   â”‚                â”‚                â”‚                   â”‚
Î±  â”¼â”€â”€â”€â”€â”€â”€â”€â”€     Î±  â”¼â”€â”€â”             â”‚ â•²              Î±  â•­â”€â”€â”€â”€â•®
   â”‚                â”‚  â””â”€â”€â”        Î± â”¼  â•²               â•±    â•²
   â”‚                â”‚     â””â”€â”€      â”‚   â•²â”€â”€            â•±       â•²
   â””â”€â”€â”€â”€â”€â”€â”€â–º       â””â”€â”€â”€â”€â”€â”€â”€â–º       â””â”€â”€â”€â”€â”€â”€â–º         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
     epochs          epochs          epochs            epochs
```

---

## Regularization

### 1. L1 and L2 Regularization

**L2 (Ridge/Weight Decay):**
$$L_{total} = L_{original} + \lambda \sum_i w_i^2$$

**L1 (Lasso):**
$$L_{total} = L_{original} + \lambda \sum_i |w_i|$$

### 2. Dropout

Randomly set activations to zero during training:

```
   Training:                    Testing:
   
   [1.0] âœ“                      [1.0]
   [0.5] âœ— â†’ 0                  [0.5]
   [0.8] âœ“          â†’           [0.8]  Ã— (1-p)
   [0.3] âœ— â†’ 0                  [0.3]
   [0.7] âœ“                      [0.7]
```

### 3. Batch Normalization

Normalize activations within each mini-batch:

$$\hat{x}_i = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}$$
$$y_i = \gamma \hat{x}_i + \beta$$

**Benefits:**
- Faster training
- Higher learning rates
- Reduces internal covariate shift

### 4. Early Stopping

```
Loss
  â”‚
  â”‚  â•² Training Loss
  â”‚   â•²
  â”‚    â•²    
  â”‚     â•²_______________
  â”‚          â•±
  â”‚         â•± Validation Loss
  â”‚   â•²    â•±
  â”‚    â•²__â•±
  â”‚       â†‘
  â”‚    STOP HERE
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Epochs
```

---

## Architectures

### Convolutional Neural Networks (CNNs)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CNN ARCHITECTURE                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                    â”‚
â”‚   INPUT     CONV    POOL    CONV    POOL    FLATTEN    FC         â”‚
â”‚                                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚     â”‚   â”‚     â”‚  â”‚   â”‚  â”‚     â”‚  â”‚   â”‚   â”‚     â”‚  â”‚     â”‚     â”‚
â”‚  â”‚Imageâ”‚ â†’ â”‚Conv â”‚â†’ â”‚Maxâ”‚â†’ â”‚Conv â”‚â†’ â”‚Maxâ”‚ â†’ â”‚  F  â”‚â†’ â”‚ FC  â”‚ â†’ y â”‚
â”‚  â”‚     â”‚   â”‚+ReLUâ”‚  â”‚Poolâ”‚  â”‚+ReLUâ”‚  â”‚Poolâ”‚  â”‚  L  â”‚  â”‚ +  â”‚     â”‚
â”‚  â”‚     â”‚   â”‚     â”‚  â”‚   â”‚  â”‚     â”‚  â”‚   â”‚   â”‚  A  â”‚  â”‚Softâ”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”˜   â”‚  T  â”‚  â”‚max â”‚     â”‚
â”‚  224Ã—224   222Ã—222  111Ã—111                  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜     â”‚
â”‚   Ã—3         Ã—32     Ã—32                       4096    1000       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Recurrent Neural Networks (RNNs)

```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                   UNROLLED RNN                   â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚                                                  â”‚
         â”‚    hâ‚€    hâ‚    hâ‚‚    hâ‚ƒ                         â”‚
         â”‚     â”‚     â”‚     â”‚     â”‚                         â”‚
         â”‚     â–¼     â–¼     â–¼     â–¼                         â”‚
         â”‚   â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â”                       â”‚
         â”‚   â”‚RNNâ”‚â†’â”‚RNNâ”‚â†’â”‚RNNâ”‚â†’â”‚RNNâ”‚â†’ ...                  â”‚
         â”‚   â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜                       â”‚
         â”‚     â–²     â–²     â–²     â–²                         â”‚
         â”‚     â”‚     â”‚     â”‚     â”‚                         â”‚
         â”‚    xâ‚€    xâ‚    xâ‚‚    xâ‚ƒ                         â”‚
         â”‚   "The" "cat" "sat" "on"                        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### LSTM (Long Short-Term Memory)

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         LSTM CELL            â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚                              â”‚
              c_{t-1} â”€â”€â”€â”€â”€â”€â”€â”€Ã—â”€â”€â”€â”€â”€â”€â”€â”€â”€+â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ c_t
                    â”‚         â”‚    â†‘    â”‚          â”‚
                    â”‚         â”‚  â”Œâ”€â”€â”€â”  â”‚          â”‚
                    â”‚         â”‚  â”‚ Ïƒ â”‚ tanh       â”‚
                    â”‚         â”‚  â””â”€â”¬â”€â”˜  â”‚          â”‚
                    â”‚         â”‚    â”‚    â”‚          â”‚
              h_{t-1} â”€â”€â”€â”€â”€â”¬â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â†’ h_t
                    â”‚      â”‚                       â”‚  â”‚
                    â”‚   â”Œâ”€â”€â”´â”€â”€â”               â”Œâ”€â”€â”´â”€â”€â”â”‚
                    â”‚   â”‚  Ïƒ  â”‚  Ïƒ   tanh     â”‚ tanhâ”‚â”‚
                    â”‚   â”‚ f_t â”‚ i_t   g_t     â”‚  o_tâ”‚â”‚
                    â”‚   â””â”€â”€â”¬â”€â”€â”˜               â””â”€â”€â”¬â”€â”€â”˜â”‚
                    â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                    â”‚              â”‚                â”‚
                    â”‚             x_t              â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Gates:
- Forget gate (f): What to forget from cell state
- Input gate (i): What new info to store
- Output gate (o): What to output
```

---

## Practical Tips

### 1. Weight Initialization
- **Xavier/Glorot**: For sigmoid/tanh - $W \sim U\left[-\sqrt{\frac{6}{n_{in}+n_{out}}}, \sqrt{\frac{6}{n_{in}+n_{out}}}\right]$
- **He**: For ReLU - $W \sim N\left(0, \sqrt{\frac{2}{n_{in}}}\right)$

### 2. Gradient Checking
Verify backprop implementation:
$$\frac{\partial L}{\partial \theta} \approx \frac{L(\theta + \epsilon) - L(\theta - \epsilon)}{2\epsilon}$$

### 3. Common Issues

| Problem | Symptoms | Solutions |
|---------|----------|-----------|
| **Vanishing Gradients** | Slow/no learning in early layers | ReLU, residual connections, LSTM |
| **Exploding Gradients** | NaN losses, unstable training | Gradient clipping, lower LR |
| **Overfitting** | Train loss â†“, Val loss â†‘ | Dropout, regularization, more data |
| **Underfitting** | Both losses high | Larger model, train longer |

### 4. Debugging Neural Networks

1. **Start small**: Overfit on a tiny dataset first
2. **Verify loss**: Check initial loss is reasonable
3. **Monitor gradients**: Look for dead neurons
4. **Visualize**: Training curves, activations, weights

---

## Resources

- ğŸ“š **Book**: "Deep Learning" by Goodfellow, Bengio, and Courville
- ğŸ“ **Course**: Stanford CS231n - CNNs for Visual Recognition
- ğŸ“ **Course**: deeplearning.ai by Andrew Ng
- ğŸ“„ **Paper**: "ImageNet Classification with Deep Convolutional Neural Networks" (AlexNet)

---

ğŸŒ [Back to Notes](README.md) | ğŸ”— [Visit jgcks.com](https://www.jgcks.com)
